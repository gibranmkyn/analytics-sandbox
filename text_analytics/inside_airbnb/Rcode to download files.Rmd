---
title: "Text mining Code"
author: "Yibo"
date: "2/16/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
---
title: "Text Mining"
author: "Yibo"
date: "2/16/2020"
output: html_document
---
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
rm(list = ls())
library(httr)
library(rvest)
library(profvis)
```

```{r}
profvis({

url <- "http://insideairbnb.com/get-the-data.html"

read_airbnb <-read_html(url)
file_url <- html_nodes(read_airbnb,xpath = "/html/body/div[4]/table[2]/tbody/tr/td[3]/a") %>% html_attr("href")

#pepare the list for each file's url
city_name_list <- data.frame()
  listings.csv.gz_urllist <- data.frame()
	  calendar.csv.gz_urllist <- data.frame()
	    reviews.csv.gz_urllist <- data.frame()
#Using for loop to get every url	
for (i in 1:103){
  #for city name
  city_name_Xpath <- paste0("/html/body/div[4]/table[",i,"]/tbody/tr[1]/td[2]")
  city_name <- html_node(read_airbnb,xpath = city_name_Xpath) %>%
  html_text()
  city_name_list <- rbind(city_name_list,as.data.frame(city_name))
  #for listings.csv.gz files
  listings.csv.gz_x_path = paste0("/html/body/div[4]/table[",i,"]/tbody/tr[1]/td[3]/a")
  listings.csv.gz <- html_nodes(read_airbnb,xpath = listings.csv.gz_x_path) %>%
  html_attr("href")
  listings.csv.gz_urllist <- rbind(listings.csv.gz_urllist,as.data.frame(listings.csv.gz))

  #for calendar.csv.gz files
  calendar.csv.gz_x_path = paste0("/html/body/div[4]/table[",i,"]/tbody/tr[2]/td[3]/a")
  calendar.csv.gz <- html_nodes(read_airbnb,xpath = calendar.csv.gz_x_path) %>%
  html_attr("href")
  calendar.csv.gz_urllist <- rbind(calendar.csv.gz_urllist,as.data.frame(calendar.csv.gz))
  
  #for reviews.csv.gz files
  reviews.csv.gz_x_path = paste0("/html/body/div[4]/table[",i,"]/tbody/tr[3]/td[3]/a")
  reviews.csv.gz <- html_nodes(read_airbnb,xpath = reviews.csv.gz_x_path) %>%
  html_attr("href")
  reviews.csv.gz_urllist <- rbind(reviews.csv.gz_urllist,as.data.frame(reviews.csv.gz))
}
url_table	<- cbind(city_name_list,listings.csv.gz_urllist,calendar.csv.gz_urllist,reviews.csv.gz_urllist)

})

```

```{r}
#download files except Zurich
for (i in 1:102){
  for (j in 2:4) {
     file_path <- paste0("dataset/",as.character(url_table[i,1]),"_",colnames(url_table)[j])
   download.file(as.character(url_table[i,j]),destfile = file_path)
  }
}



```


