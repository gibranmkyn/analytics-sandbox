x[1,]
x[,listing_id]
x[,'listing_id']
x[1,]
x[1,apt]
x[,apt]
x[,'apt']
x[,'listing_id']
x <- as.data.frame(as.matrix(dtm_train_tfidf))
x
rownames(x)
x$listing_id <- rownames(x)
x[1,]
x[1,] %>%
select(listing_id)
x <- as.data.frame(as.matrix(dtm_train_tfidf)) %>%
mutate(listing_id = rownames(x))
x[1,] %>%
select(listing_id)
x <- as.data.frame(as.matrix(dtm_train_tfidf)) %>%
mutate(listing_id = rownames())
x <- as.data.frame(as.matrix(dtm_train_tfidf))
x$listing_id <- rownames(x)
x[1,] %>%
select(listing_id)
df <- listing_sample %>%
select(listing_id, description, amenities)
library(text2vec)
df <- listing_sample %>%
select(listing_id, description, amenities)
# define preprocessing function and tokenization function
prep_fun = tolower
tok_fun = word_tokenizer
it_train = itoken(df$amenities,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = df$listing_id,
progressbar = TRUE)
vocab = create_vocabulary(it_train, stopwords = quanteda::stopwords("en"), ngram = c(1L, 2L))
pruned_vocab = prune_vocabulary(vocab,
term_count_min = 10,
doc_proportion_max = 0.5,
doc_proportion_min = 0.001)
vectorizer = vocab_vectorizer(pruned_vocab)
dtm_train  = create_dtm(it_train, vectorizer)
tfidf = TfIdf$new()
dtm_train_tfidf = fit_transform(dtm_train, tfidf)
summary(dtm_train_tfidf)
x <- as.data.frame(as.matrix(dtm_train_tfidf))
x$listing_id <- rownames(x)
x
dtm_train_tfidf
jsPCA_robust(dtm_train_tfidf)
groupedCalendarAll <- combinedCalendar %>%
group_by(date = date) %>%
summarise(average_price = mean(price, na.rm = TRUE)) %>%
mutate(year = as.factor(as.character(year(date))))
# ----- dataprep calendar
ams_calendar2020 <- read_csv('temp/amsterdam_012020_calendar.csv.gz') %>% select(listing_id, date, available, price)
ams_calendar2019 <- read_csv('temp/amsterdam_012019_calendar.csv.gz') %>% select(listing_id, date, available, price)
ams_calendar2018 <- read_csv('temp/amsterdam_042018_calendar.csv.gz') %>% select(listing_id, date, available, price)
combinedCalendar <- rbind(ams_calendar2020, ams_calendar2019, ams_calendar2018) %>%
filter(year(date) <= 2019) %>%
mutate(booked = ifelse(available==FALSE, 1, 0)) %>%
mutate(price = as.numeric(gsub(",", "", substring(price, 2))))  %>%
mutate(listing_id = as.character(listing_id))
rm(ams_calendar2020)
rm(ams_calendar2019)
rm(ams_calendar2018)
listings_calendar <- combinedCalendar %>%
group_by(listing_id) %>%
summarise(total_booked = sum(booked, na.rm = TRUE), total_dates = n(), average_price = mean(price, na.rm = TRUE)) %>%
mutate(percent_booked = (total_booked/total_dates)*100)
final_df <- listing_sample %>%
#  inner_join(review_agg, by = 'listing_id') %>% # inner join is used to ensure that the selected listings has reviews
inner_join(listings_calendar %>% select(listing_id, average_price, percent_booked), by = 'listing_id')
#rm(review_agg)
final_df
library(text2vec)
t1 <- Sys.time()
df <- listing_sample %>%
select(listing_id, description, amenities)
# define preprocessing function and tokenization function
prep_fun = tolower
tok_fun = word_tokenizer
it_train = itoken(final_df$description,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = final_df$listing_id,
progressbar = TRUE)
vocab = create_vocabulary(it_train, stopwords = quanteda::stopwords("en"), ngram = c(1L, 2L))
pruned_vocab = prune_vocabulary(vocab,
term_count_min = 10,
doc_proportion_max = 0.5,
doc_proportion_min = 0.001)
vectorizer = vocab_vectorizer(pruned_vocab)
dtm_train  = create_dtm(it_train, vectorizer)
tfidf = TfIdf$new()
dtm_train_tfidf = fit_transform(dtm_train, tfidf)
summary(dtm_train_tfidf)
x <- as.data.frame(as.matrix(dtm_train_tfidf))
x$listing_id <- rownames(x)
t2 <- Sys.time()
t2 - t1
x
final_df
x %>%
left_join(final_df %>% select(listing_id, average_price))
x %>%
left_join(final_df %>% select(listing_id, average_price), by = 'listing_id')
pred_x <- x %>%
left_join(final_df %>% select(listing_id, average_price), by = 'listing_id')
pred_x
pred_x %>% select(average_price)
pred_x <- x %>%
inner_join(final_df %>% select(listing_id, average_price), by = 'listing_id')
pred_x
x
x <- as.data.frame(as.matrix(dtm_train_tfidf))
x
library(text2vec)
t1 <- Sys.time()
df <- listing_sample %>%
select(listing_id, description, amenities)
# define preprocessing function and tokenization function
prep_fun = tolower
tok_fun = word_tokenizer
it_train = itoken(final_df$description,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = final_df$listing_id,
progressbar = TRUE)
vocab = create_vocabulary(it_train, stopwords = quanteda::stopwords("en"), ngram = c(1L, 2L))
pruned_vocab = prune_vocabulary(vocab,
term_count_min = 10,
doc_proportion_max = 0.5,
doc_proportion_min = 0.001)
vectorizer = vocab_vectorizer(pruned_vocab)
dtm_train  = create_dtm(it_train, vectorizer)
tfidf = TfIdf$new()
dtm_train_tfidf = fit_transform(dtm_train, tfidf)
summary(dtm_train_tfidf)
x <- as.data.frame(as.matrix(dtm_train_tfidf))
x$listing_id <- rownames(x)
pred_x <- x %>%
inner_join(final_df %>% select(listing_id, average_price), by = 'listing_id')
t2 <- Sys.time()
t2 - t1
modelx <- lm(log(pred_x$average_price)~.)
modelx <- lm(log(average_price)~., data = pred_x)
summary(modelx)
pred_x
summary(modelx)
pred_x
summary(modelx)
library(text2vec)
t1 <- Sys.time()
df <- listing_sample %>%
select(listing_id, description, amenities)
# define preprocessing function and tokenization function
prep_fun = tolower
tok_fun = word_tokenizer
it_train = itoken(final_df$amenities,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = final_df$listing_id,
progressbar = TRUE)
vocab = create_vocabulary(it_train, stopwords = quanteda::stopwords("en"), ngram = c(1L, 2L))
pruned_vocab = prune_vocabulary(vocab,
term_count_min = 10,
doc_proportion_max = 0.5,
doc_proportion_min = 0.001)
vectorizer = vocab_vectorizer(pruned_vocab)
dtm_train  = create_dtm(it_train, vectorizer)
tfidf = TfIdf$new()
dtm_train_tfidf = fit_transform(dtm_train, tfidf)
summary(dtm_train_tfidf)
x <- as.data.frame(as.matrix(dtm_train_tfidf))
x$listing_id <- rownames(x)
pred_x <- x %>%
inner_join(final_df %>% select(listing_id, average_price), by = 'listing_id')
t2 <- Sys.time()
t2 - t1
modelx <- lm(log(average_price)~., data = pred_x)
summary(modelx)
modelx <- linearRidge(log(average_price)~., data = pred_x)
install.packages('ridge')
library(ridge)
modelx <- linearRidge(log(average_price)~., data = pred_x)
summary(modelx)
set.seed(100) # set seed to replicate results
trainingIndex <- sample(1:nrow(inputData), 0.8*nrow(pred_x)) # indices for 80% training data
set.seed(100) # set seed to replicate results
trainingIndex <- sample(1:nrow(pred_x), 0.8*nrow(pred_x)) # indices for 80% training data
trainingData <- pred_x[trainingIndex, ] # training data
testData <- pred_x[-trainingIndex, ] # test data
trainingData
library(ridge)
set.seed(100) # set seed to replicate results
trainingIndex <- sample(1:nrow(pred_x), 0.8*nrow(pred_x)) # indices for 80% training data
trainingData <- pred_x[trainingIndex, ] # training data
testData <- pred_x[-trainingIndex, ] # test data
modelx <- linearRidge(log(average_price)~., data = trainingData)
predicted <- predict(linRidgeMod, testData)  # predict on test data
library(ridge)
set.seed(100) # set seed to replicate results
trainingIndex <- sample(1:nrow(pred_x), 0.8*nrow(pred_x)) # indices for 80% training data
trainingData <- pred_x[trainingIndex, ] # training data
testData <- pred_x[-trainingIndex, ] # test data
modelx <- linearRidge(log(average_price)~., data = trainingData)
predicted <- predict(modelx, testData)  # predict on test data
modelx
predicted <- predict(modelx, testData)  # predict on test data
predicted <- predict(modelx, testData)  # predict on test data
predicted <- predict(modelx, testData)  # predict on test data
testData
trainingData
modelx <- linearRidge(log(average_price)~., data = trainingData)
modelx
predicted <- predict(modelx, testData)  # predict on test data
predicted <- predict(modelx, testData)  # predict on test data
predicted
predicted <- predict(modelx, testData)  # predict on test data
predicted <- predict(modelx, testData)  # predict on test data
modelx
modelx <- linearRidge(log(average_price)~., data = trainingData %>% select(-listing_id))
predicted <- predict(modelx, testData)  # predict on test data
compare <- cbind (actual=testData$response, predicted)  # combine
mean (apply(compare, 1, min)/apply(compare, 1, max)) # calculate accuracy
mean (apply(compare, 1, min)/apply(compare, 1, max)) # calculate accuracy
predicted
compare
predicted
compare <- cbind (actual=testData$response, predicted)  # combine
mean (apply(compare, 1, min)/apply(compare, 1, max)) # calculate accuracy
library(ridge)
set.seed(100) # set seed to replicate results
trainingIndex <- sample(1:nrow(pred_x), 0.8*nrow(pred_x)) # indices for 80% training data
trainingData <- pred_x[trainingIndex, ] # training data
testData <- pred_x[-trainingIndex, ] # test data
modelx <- lm(log(average_price)~., data = trainingData %>% select(-listing_id))
predicted <- predict(modelx, testData)  # predict on test data
compare <- cbind (actual=testData$response, predicted)  # combine
mean (apply(compare, 1, min)/apply(compare, 1, max)) # calculate accuracy
modelx
summary(modelx)
modelx <- linearRidge(log(average_price)~., data = trainingData %>% select(-listing_id))
summary(modelx)
modelx <- linearRidge(log(average_price)~., data = trainingData %>% select(-listing_id))
modely <- lm(log(average_price)~., data = trainingData %>% select(-listing_id))
summary(modelx)
summary(modely)
listings_calendar
combinedCalendar
listings_calendar <- combinedCalendar %>%
mutate(year_month =  format(date,"%Y-%m")) %>%
group_by(listing_id, year_month) %>%
summarise(total_booked = sum(booked, na.rm = TRUE), total_dates = n(), average_price = mean(price, na.rm = TRUE)) %>%
mutate(percent_booked = (total_booked/total_dates)*100)
listings_calendar
listings_calendar <- combinedCalendar %>%
mutate(year_month =  format(date,"%Y-%m")) %>%
group_by(listing_id, year_month) %>%
summarise(total_booked = sum(booked, na.rm = TRUE), total_dates = n(), average_price = mean(price, na.rm = FALSE)) %>%
mutate(percent_booked = (total_booked/total_dates)*100)
listings_calendar
listings_calendar <- combinedCalendar %>%
mutate(year_month =  format(date,"%Y-%m")) %>%
group_by(listing_id, year_month) %>%
summarise(total_booked = sum(booked, na.rm = TRUE), total_dates = n(), average_price = mean(price)) %>%
mutate(percent_booked = (total_booked/total_dates)*100)
listings_calendar
listings_calendar <- combinedCalendar %>%
mutate(year_month =  format(date,"%Y-%m")) %>%
group_by(listing_id, year_month) %>%
summarise(total_booked = sum(booked, na.rm = TRUE), total_dates = n(), average_price = mean(price, na.rm = TRUE)) %>%
mutate(percent_booked = (total_booked/total_dates)*100)
combinedCalendar
combinedCalendar %>%
mutate(year_month =  format(date,"%Y-%m")) %>%
group_by(listing_id, year_month) %>%
summarise(average_price = mean(price, na.rm = TRUE))
combinedCalendar %>%
mutate(year_month =  format(date,"%Y-%m"))
listings_df <- readr::read_csv( paste0(temp_city_folder,"/listings.csv.gz"))
listings_calendar <- combinedCalendar %>%
mutate(year_month =  format(date,"%Y-%m")) %>%
group_by(listing_id, year_month) %>%
summarise(total_booked = sum(booked, na.rm = TRUE), total_dates = n(), average_price = mean(price, na.rm = TRUE)) %>%
mutate(percent_booked = (total_booked/total_dates)*100)
listings_calendar
combinedCalendar %>%
mutate(year_month =  format(date,"%Y-%m")) %>%
filter(listing_id == '10023540', year_month == '2018-04')
combinedCalendar %>%
filter(listing_id == '10023540') %>%
mutate(year_month =  format(date,"%Y-%m")) %>%
filter(year_month == '2018-04')
listings_calendar <- combinedCalendar %>%
mutate(year_month =  format(date,"%Y-%m")) %>%
group_by(listing_id, year_month) %>%
summarise(total_booked = sum(booked, na.rm = TRUE), total_dates = n(), average_price = mean(price, na.rm = TRUE)) %>%
mutate(percent_booked = (total_booked/total_dates)*100) %>%
arrange(listing_id, desc(year_month))
listings_calendar
install.packages('zoo')
library(zoo)
listings_calendar <- combinedCalendar %>%
mutate(year_month =  format(date,"%Y-%m")) %>%
group_by(listing_id, year_month) %>%
summarise(total_booked = sum(booked, na.rm = TRUE), total_dates = n(), average_price = mean(price, na.rm = TRUE)) %>%
mutate(percent_booked = (total_booked/total_dates)*100) %>%
arrange(listing_id, desc(year_month)) %>%
mutate(average_price = na.locf(average_price))
combinedCalendar %>%
mutate(year_month =  format(date,"%Y-%m")) %>%
group_by(listing_id, year_month) %>%
summarise(total_booked = sum(booked, na.rm = TRUE), total_dates = n(), average_price = mean(price, na.rm = TRUE)) %>%
mutate(percent_booked = (total_booked/total_dates)*100) %>%
arrange(listing_id, desc(year_month))
na.locf(listings_calendar$average_price)
listings_calendar
na.locf(listings_calendar$average_price)
listings_calendar
listings_calendar <- combinedCalendar %>%
mutate(year_month =  format(date,"%Y-%m")) %>%
group_by(listing_id, year_month) %>%
summarise(total_booked = sum(booked, na.rm = TRUE), total_dates = n(), average_price = mean(price, na.rm = TRUE)) %>%
mutate(percent_booked = (total_booked/total_dates)*100) %>%
arrange(listing_id, desc(year_month))
listings_calendar
listings_calendar <- combinedCalendar %>%
mutate(year_month =  format(date,"%Y-%m")) %>%
group_by(listing_id, year_month) %>%
summarise(total_booked = sum(booked, na.rm = TRUE), total_dates = n(), average_price = mean(price, na.rm = TRUE)) %>%
mutate(percent_booked = (total_booked/total_dates)*100) %>%
arrange(listing_id, desc(year_month))
listings_calendar
combinedCalendar %>%
filter(price is.na)
combinedCalendar %>%
filter(price == is.na)
combinedCalendar %>%
filter(is.na(price))
combinedCalendar %>%
arrange(listing_id, date)
mutate(price_filled = na.locf(price))
combinedCalendar %>%
arrange(listing_id, date) %>%
mutate(price_filled = na.locf(price))
combinedCalendar %>%
arrange(listing_id, desc(date)) %>%
mutate(price_filled = na.locf(price)) %>%
filter
combinedCalendar %>%
arrange(listing_id, desc(date)) %>%
mutate(price_filled = na.locf(price), year_month =  format(date,"%Y-%m")) %>%
group_by(listing_id, year_month) %>%
summarise(total_booked = sum(booked, na.rm = TRUE), total_dates = n(), average_price = mean(price, na.rm = TRUE)) %>%
mutate(percent_booked = (total_booked/total_dates)*100)
combinedCalendar %>%
arrange(listing_id, desc(date)) %>%
mutate(price_filled = na.locf(price), year_month =  format(date,"%Y-%m")) %>%
group_by(listing_id, year_month) %>%
summarise(total_booked = sum(booked, na.rm = TRUE), total_dates = n(), average_price = mean(price_filled, na.rm = TRUE)) %>%
mutate(percent_booked = (total_booked/total_dates)*100)
listings_calendar <- combinedCalendar %>%
arrange(listing_id, desc(date)) %>%
mutate(price_filled = na.locf(price), year_month =  format(date,"%Y-%m")) %>%
group_by(listing_id, year_month) %>%
summarise(total_booked = sum(booked, na.rm = TRUE), total_dates = n(), average_price = mean(price_filled, na.rm = TRUE)) %>%
mutate(percent_booked = (total_booked/total_dates)*100)
listings_calendar
ggpplot(listings_calendar, aes(x = year_month, y = average_price)) +
geom_line
ggplot(listings_calendar, aes(x = year_month, y = average_price)) +
geom_line
ggplot(listings_calendar, aes(x = year_month, y = average_price)) +
geom_point
ggplot(listings_calendar, aes(x = year_month, y = average_price)) +
geom_point
library(ggplot2)
ggplot(listings_calendar, aes(x = year_month, y = average_price)) +
geom_point
listings_calendar
ggplot(listings_calendar, aes(x = year_month, y = average_price)) +
geom_point
ggplot(listings_calendar, aes(x = year_month, y = average_price))
ggplot(listings_calendar, aes(x = year_month, y = average_price, fill = listing_id)) +
geom_point
ggplot(listings_calendar, aes(x = year_month, y = average_price, fill = listing_id)) +
geom_point
ggplot(listings_calendar, aes(x = year_month, y = average_price, fill = listing_id)) +
geom_point
ggplot(listings_calendar, aes(x = year_month, y = average_price, fill = listing_id)) +
geom_point()
ggplot(listings_calendar, aes(x = year_month, y = average_price, fill = listing_id)) +
geom_line()
ggplot(listings_calendar, aes(x = year_month, y = average_price, group = listing_id)) +
geom_line()
pred_x
library(text2vec)
t1 <- Sys.time()
df <- listing_sample %>%
select(listing_id, description, amenities)
# define preprocessing function and tokenization function
prep_fun = tolower
tok_fun = word_tokenizer
it_train = itoken(final_df$amenities,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = final_df$listing_id,
progressbar = TRUE)
vocab = create_vocabulary(it_train, stopwords = quanteda::stopwords("en"), ngram = c(1L, 2L))
pruned_vocab = prune_vocabulary(vocab,
term_count_min = 10,
doc_proportion_max = 0.5,
doc_proportion_min = 0.001)
vectorizer = vocab_vectorizer(pruned_vocab)
dtm_train  = create_dtm(it_train, vectorizer)
tfidf = TfIdf$new()
dtm_train_tfidf = fit_transform(dtm_train, tfidf)
summary(dtm_train_tfidf)
x <- as.data.frame(as.matrix(dtm_train_tfidf))
x$listing_id <- rownames(x)
pred_x <- x %>%
inner_join(final_df %>% select(listing_id, average_price), by = 'listing_id')
t2 <- Sys.time()
t2 - t1
hist(average_price)
hist(trainingData$average_price)
hist(trainingData$average_price, breaks = 200)
hist(log(trainingData$average_price), breaks = 200)
hist(trainingData$average_price, breaks = 200)
hist(log(trainingData$average_price), breaks = 200)
hist(trainingData$average_price, breaks = 200)
hist(log(trainingData$average_price), breaks = 200)
hist(trainingData$average_price, breaks = 200)
hist(log(trainingData$average_price), breaks = 200)
hist(trainingData$average_price, breaks = 200)
hist(log(trainingData$average_price), breaks = 200)
pred_x
mean (apply(compare, 1, min)/apply(compare, 1, max)) # calculate accuracy
set.seed(100) # set seed to replicate results
trainingIndex <- sample(1:nrow(pred_x), 0.8*nrow(pred_x)) # indices for 80% training data
trainingData <- pred_x[trainingIndex, ] # training data
testData <- pred_x[-trainingIndex, ] # test data
modelx <- linearRidge(log(average_price)~lag(.), data = trainingData %>% select(-listing_id))
library(ridge)
set.seed(100) # set seed to replicate results
trainingIndex <- sample(1:nrow(pred_x), 0.8*nrow(pred_x)) # indices for 80% training data
trainingData <- pred_x[trainingIndex, ] # training data
testData <- pred_x[-trainingIndex, ] # test data
modelx <- linearRidge(log(average_price)~., data = trainingData %>% select(-listing_id))
modely <- lm(log(average_price)~lag., data = trainingData %>% select(-listing_id))
modely <- lm(log(average_price)~., data = trainingData %>% select(-listing_id))
summary(modelx)
summary(modely)
dtm_train
dtm_train_tfidf
# ----- dataprep calendar
ams_calendar2020 <- read_csv('temp/amsterdam_012020_calendar.csv.gz') %>% select(listing_id, date, available, price)
ams_calendar2020 <- read_csv('temp/amsterdam_012020_calendar.csv.gz') %>% select(listing_id, date, available, price)
ams_calendar2019 <- read_csv('temp/amsterdam_012019_calendar.csv.gz') %>% select(listing_id, date, available, price)
ams_calendar2018 <- read_csv('temp/amsterdam_042018_calendar.csv.gz') %>% select(listing_id, date, available, price)
ams_calendar2020
ams_calendar2018
ams_calendar2019
ams_calendar2020
ams_calendar2020 %>%
filter(year(date) == 2019)
ams_calendar2020 %>%
filter(year(date) == 2020)
listing_sample
listings_calendar
vocab
library(text2vec)
t1 <- Sys.time()
df <- listing_sample %>%
select(listing_id, description, amenities)
# define preprocessing function and tokenization function
prep_fun = tolower
tok_fun = word_tokenizer
it_train = itoken(final_df$amenities,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = final_df$listing_id,
progressbar = TRUE)
vocab = create_vocabulary(it_train, stopwords = quanteda::stopwords("en"), ngram = c(1L, 2L))
pruned_vocab = prune_vocabulary(vocab,
term_count_min = 10,
doc_proportion_max = 0.5,
doc_proportion_min = 0.001)
vectorizer = vocab_vectorizer(pruned_vocab)
dtm_train  = create_dtm(it_train, vectorizer)
tfidf = TfIdf$new()
dtm_train_tfidf = fit_transform(dtm_train, tfidf)
summary(dtm_train_tfidf)
x <- as.data.frame(as.matrix(dtm_train_tfidf))
x$listing_id <- rownames(x)
pred_x <- x %>%
inner_join(final_df %>% select(listing_id, average_price), by = 'listing_id')
t2 <- Sys.time()
t2 - t1
vocab
pruned_vocab
vocab
pruned_vocab
pruned_vocab
vocab
vocab
pruned_vocab
