}
return(main_df)
}
# Generate the sample
listings_sample <- get_sample(folder_path = "dataset", pattern = "listings.csv.gz")
rm(list = ls()) # cleans the memory
library(xml2)
library(rvest)
library(stringr)
library(dplyr)
library(tm)
library(qdap) # Quantitative Discourse Analysis Package
library(ggplot2)
library(tidyr)
library(RCurl) # download files
library(readr) # read from zip
library(stringr)
library(RSQLite)
# library(plyr)
rm(list = ls()) # cleans the memory
library(xml2)
library(rvest)
library(stringr)
library(dplyr)
library(tm)
library(qdap) # Quantitative Discourse Analysis Package
library(ggplot2)
library(tidyr)
library(RCurl) # download files
library(readr) # read from zip
library(stringr)
library(RSQLite)
# library(plyr)
# ----- Pre- ETL investigation to get all columns and select the columns needed
# Create a function to make a sample of 1 row from each dataset and combine them to get an idea what columns we have
get_sample <- function(folder_path, pattern) {
listed_files <- list.files(folder_path, pattern = pattern)
main_df <- data.frame()
for (i in 1:length(listed_files)) {
file_path <-paste(folder_path, listed_files[i],sep="/")
local_df <- read.csv(file_path, nrows= 1, stringsAsFactors=FALSE)
local_df$file_name <-listed_files[i]
main_df <- plyr::rbind.fill(main_df, local_df)
}
return(main_df)
}
# Generate the sample
listings_sample <- get_sample(folder_path = "dataset", pattern = "listings.csv.gz")
reviews_sample <- get_sample(folder_path = "dataset", pattern = "reviews.csv.gz")
names(listings_sample)
names(reviews_sample)
# ----- Initiation
conn <- dbConnect(RSQLite::SQLite(), "inside_airbnb.db") # connect to SQLite db, in this case, it created a new db
folder_path <- "dataset"
listings_list <-list.files(folder_path, pattern = "listings.csv.gz")
reviews_list <-list.files(folder_path, pattern = "reviews.csv.gz")
# ----- ETL normalised reviews.csv.gz
for (i in 1:length(reviews_list)) {
file_path <-paste(folder_path, reviews_list[i],sep="/")
reviews_data <- read_csv(file_path)
reviews_data$file_name <- reviews_list[i]
reviewers_table <- reviews_data %>%
distinct(reviewer_id, reviewer_name)
reviews_table <- reviews_data %>%
select(-reviewer_name)
dbWriteTable(conn,"review", reviews_table, append = TRUE)
dbWriteTable(conn,"reviewer", reviewers_table, append = TRUE)
}
dbQuery(conn,"SELECT count(*) FROM review")
dbGetQuery(conn,"SELECT count(*) FROM review")
reviews_sample %>%
select(-xxx)
normalise_listings <- function(listings_data) {
hosts_table <- listings_data %>%
select(starts_with('host')) %>%
distinct(host_id, .keep_all = TRUE)
listings_table <- listings_data %>%
select(-c(contains('url'), startsWith('host')))
dbWriteTable(conn,"host", hosts_table, append = TRUE)
dbWriteTable(conn,"listing", listings_table, append = TRUE)
}
normalise_listings(listings_sample)
start_time <- Sys.time()
# ----- Initiation
conn <- dbConnect(RSQLite::SQLite(), "inside_airbnb.db") # connect to SQLite db, in this case, it created a new db
folder_path <- "dataset"
listings_list <-list.files(folder_path, pattern = "listings.csv.gz")
reviews_list <-list.files(folder_path, pattern = "reviews.csv.gz")
normalise_listings <- function(listings_data) {
hosts_table <- listings_data %>%
select(starts_with('host')) %>%
distinct(host_id, .keep_all = TRUE)
listings_table <- listings_data %>%
select(-c(contains('url'), startsWith('host')))
dbWriteTable(conn,"host", hosts_table, append = TRUE)
dbWriteTable(conn,"listing", listings_table, append = TRUE)
}
normalise_listings(listings_sample)
start_time <- Sys.time()
# ----- Initiation
conn <- dbConnect(RSQLite::SQLite(), "inside_airbnb.db") # connect to SQLite db, in this case, it created a new db
folder_path <- "dataset"
listings_list <-list.files(folder_path, pattern = "listings.csv.gz")
reviews_list <-list.files(folder_path, pattern = "reviews.csv.gz")
normalise_listings <- function(listings_data) {
hosts_table <- listings_data %>%
select(starts_with('host')) %>%
distinct(host_id, .keep_all = TRUE)
listings_table <- listings_data %>%
select(-contains('url'), -startsWith('host'))
dbWriteTable(conn,"host", hosts_table, append = TRUE)
dbWriteTable(conn,"listing", listings_table, append = TRUE)
}
normalise_listings(listings_sample)
listings_sample
names(listings_sample)
start_time <- Sys.time()
# ----- Initiation
conn <- dbConnect(RSQLite::SQLite(), "inside_airbnb.db") # connect to SQLite db, in this case, it created a new db
folder_path <- "dataset"
listings_list <-list.files(folder_path, pattern = "listings.csv.gz")
reviews_list <-list.files(folder_path, pattern = "reviews.csv.gz")
normalise_listings <- function(listings_data) {
hosts_table <- listings_data %>%
select(starts_with('host')) %>%
distinct(host_id, .keep_all = TRUE)
listings_table <- listings_data %>%
select(-c(contains('url'), startsWith('host')))
dbWriteTable(conn,"host", hosts_table, append = TRUE)
dbWriteTable(conn,"listing", listings_table, append = TRUE)
}
normalise_listings(listings_sample)
start_time <- Sys.time()
# ----- Initiation
conn <- dbConnect(RSQLite::SQLite(), "inside_airbnb.db") # connect to SQLite db, in this case, it created a new db
folder_path <- "dataset"
listings_list <-list.files(folder_path, pattern = "listings.csv.gz")
reviews_list <-list.files(folder_path, pattern = "reviews.csv.gz")
normalise_listings <- function(listings_data) {
hosts_table <- listings_data %>%
select(starts_with('host')) %>%
distinct(host_id, .keep_all = TRUE)
listings_table <- listings_data %>%
select(-c(contains('url'), starts_with('host')))
dbWriteTable(conn,"host", hosts_table, append = TRUE)
dbWriteTable(conn,"listing", listings_table, append = TRUE)
}
normalise_listings(listings_sample)
dbGetQuery(conn, 'SELECT * FROM host limit 3')
names(listings_table)
names(listings_table)
names(listings_table)
listings_table
listings_table
dbGetQuery(conn, 'SELECT * FROM listing limit 3')
dbGetQuery(conn, 'SELECT host_id FROM listing limit 3')
start_time <- Sys.time()
# ----- Initiation
conn <- dbConnect(RSQLite::SQLite(), "inside_airbnb.db") # connect to SQLite db, in this case, it created a new db
folder_path <- "dataset"
listings_list <-list.files(folder_path, pattern = "listings.csv.gz")
reviews_list <-list.files(folder_path, pattern = "reviews.csv.gz")
normalise_listings <- function(listings_data) {
hosts_table <- listings_data %>%
select(starts_with('host')) %>%
distinct(host_id, .keep_all = TRUE)
listings_table <- listings_data %>%
select(-c(contains('url'), host_name:host_has_profile_pic))
dbWriteTable(conn,"host", hosts_table, append = TRUE)
dbWriteTable(conn,"listing", listings_table, append = TRUE)
}
normalise_listings(listings_sample)
dbGetQuery(conn, 'SELECT host_id FROM listing limit 3')
dbGetQuery(conn, 'SELECT host_name FROM listing limit 3')
dbGetQuery(conn, 'SELECT * FROM listing limit 3')
start_time <- Sys.time()
# ----- Initiation
conn <- dbConnect(RSQLite::SQLite(), "inside_airbnb.db") # connect to SQLite db, in this case, it created a new db
folder_path <- "dataset"
listings_list <-list.files(folder_path, pattern = "listings.csv.gz")
reviews_list <-list.files(folder_path, pattern = "reviews.csv.gz")
normalise_listings <- function(listings_data) {
hosts_table <- listings_data %>%
select(starts_with('host')) %>%
distinct(host_id, .keep_all = TRUE)
listings_table <- listings_data %>%
select(-c(contains('url'), host_name:host_identity_verified))
dbWriteTable(conn,"host", hosts_table, append = TRUE)
dbWriteTable(conn,"listing", listings_table, append = TRUE)
}
normalise_listings(listings_sample)
dbGetQuery(conn, 'SELECT * FROM listing limit 3')
start_time <- Sys.time()
# ----- Initiation
conn <- dbConnect(RSQLite::SQLite(), "inside_airbnb.db") # connect to SQLite db, in this case, it created a new db
folder_path <- "dataset"
listings_list <-list.files(folder_path, pattern = "listings.csv.gz")
reviews_list <-list.files(folder_path, pattern = "reviews.csv.gz")
normalise_listings <- function(listings_data) {
hosts_table <- listings_data %>%
select(starts_with('host')) %>%
distinct(host_id, .keep_all = TRUE)
listings_table <- listings_data %>%
select(-c(contains('url'), host_name:host_identity_verified))
dbWriteTable(conn,"host", hosts_table, append = TRUE)
dbWriteTable(conn,"listing", listings_table, append = TRUE)
}
normalise_listings(listings_sample)
dbGetQuery(conn, 'SELECT * FROM listing limit 3')
normalise_reviews <- function(reviews_data) {
reviewers_table <- reviews_data %>%
distinct(reviewer_id, reviewer_name)
reviews_table <- reviews_data %>%
select(-reviewer_name)
dbWriteTable(conn,"review", reviews_table, append = TRUE)
dbWriteTable(conn,"reviewer", reviewers_table, append = TRUE)
}
normalise_reviews(reviews_sample)
normalise_reviews <- function(reviews_data) {
reviewers_table <- reviews_data %>%
distinct(reviewer_id, reviewer_name)
reviews_table <- reviews_data %>%
select(-reviewer_name)
dbWriteTable(conn,"review", reviews_table, append = TRUE)
dbWriteTable(conn,"reviewer", reviewers_table, append = TRUE)
}
normalise_reviews(reviews_sample)
normalise_listings <- function(listings_data) {
hosts_table <- listings_data %>%
select(starts_with('host')) %>%
distinct(host_id, .keep_all = TRUE)
listings_table <- listings_data %>%
select(-c(contains('url'), host_name:host_identity_verified))
dbWriteTable(conn,"host", hosts_table, append = TRUE)
dbWriteTable(conn,"listing", listings_table, append = TRUE)
}
normalise_reviews <- function(reviews_data) {
reviewers_table <- reviews_data %>%
distinct(reviewer_id, reviewer_name)
reviews_table <- reviews_data %>%
select(-reviewer_name)
dbWriteTable(conn,"review", reviews_table, append = TRUE)
dbWriteTable(conn,"reviewer", reviewers_table, append = TRUE)
}
normalise_reviews <- function(reviews_data) {
reviewers_table <- reviews_data %>%
distinct(reviewer_id, reviewer_name)
reviews_table <- reviews_data %>%
select(-reviewer_name)
dbWriteTable(conn,"review", reviews_table, append = TRUE)
dbWriteTable(conn,"reviewer", reviewers_table, append = TRUE)
}
normalise_reviews(reviews_sample)
# ----- Initiation
conn <- dbConnect(RSQLite::SQLite(), "inside_airbnb.db") # connect to SQLite db, in this case, it created a new db
normalise_reviews <- function(reviews_data) {
reviewers_table <- reviews_data %>%
distinct(reviewer_id, reviewer_name)
reviews_table <- reviews_data %>%
select(-reviewer_name)
dbWriteTable(conn,"review", reviews_table, append = TRUE)
dbWriteTable(conn,"reviewer", reviewers_table, append = TRUE)
}
normalise_reviews(reviews_sample)
dbGetQuery(conn, 'SELECT * FROM review limit 3')
dbGetQuery(conn, 'SELECT * FROM review')
start_time <- Sys.time()
# ----- Initiation
conn <- dbConnect(RSQLite::SQLite(), "inside_airbnb.db") # connect to SQLite db, in this case, it created a new db
folder_path <- "dataset"
listings_list <-list.files(folder_path, pattern = "listings.csv.gz")
reviews_list <-list.files(folder_path, pattern = "reviews.csv.gz")
normalise_listings <- function(listings_data) {
hosts_table <- listings_data %>%
select(starts_with('host')) %>%
distinct(host_id, .keep_all = TRUE)
listings_table <- listings_data %>%
select(-c(contains('url'), host_name:host_identity_verified))
dbWriteTable(conn,"host", hosts_table, append = TRUE)
dbWriteTable(conn,"listing", listings_table, append = TRUE)
}
normalise_reviews <- function(reviews_data) {
reviewers_table <- reviews_data %>%
distinct(reviewer_id, reviewer_name)
reviews_table <- reviews_data %>%
select(-reviewer_name)
dbWriteTable(conn,"review", reviews_table, append = TRUE)
dbWriteTable(conn,"reviewer", reviewers_table, append = TRUE)
}
# ----- Automatically use sample data to create schema
normalise_reviews(reviews_sample)
normalise_listings(listings_sample)
dbGetQuery("SELECT * FROM review")
dbGetQuery(conn, "SELECT * FROM review")
dbGetQuery(conn, "SELECT * FROM host")
dbGetQuery(conn, "SELECT * FROM reviewer")
dbGetQuery(conn, "SELECT * FROM listing")
dbGetQuery(conn, "DELETE FROM review; DELETE FROM reviewer; DELETE FROM listing; DELETE FROM host;")
dbGetQuery(conn, "SELECT * FROM listing")
dbGetQuery(conn, "SELECT * FROM listing")
dbGetQuery(conn, "DELETE FROM review; DELETE FROM reviewer; DELETE FROM listing; DELETE FROM host;")
dbGetQuery(conn, "SELECT * FROM listing")
dbGetQuery(conn, "SELECT * FROM review")
dbGetQuery(conn, "DELETE FROM host")
dbGetQuery(conn, "DELETE FROM review")
dbGetQuery(conn, "DELETE FROM reviewer")
dbGetQuery(conn, "DELETE FROM listing")
dbGetQuery(conn, "DELETE FROM host")
start_time <- Sys.time()
# ----- Initiation
conn <- dbConnect(RSQLite::SQLite(), "inside_airbnb.db") # connect to SQLite db, in this case, it created a new db
folder_path <- "dataset"
listings_list <-list.files(folder_path, pattern = "listings.csv.gz")
reviews_list <-list.files(folder_path, pattern = "reviews.csv.gz")
normalise_listings <- function(listings_data) {
hosts_table <- listings_data %>%
select(starts_with('host')) %>%
distinct(host_id, .keep_all = TRUE)
listings_table <- listings_data %>%
select(-c(contains('url'), host_name:host_identity_verified))
dbWriteTable(conn,"host", hosts_table, append = TRUE)
dbWriteTable(conn,"listing", listings_table, append = TRUE)
}
normalise_reviews <- function(reviews_data) {
reviewers_table <- reviews_data %>%
distinct(reviewer_id, reviewer_name)
reviews_table <- reviews_data %>%
select(-reviewer_name)
dbWriteTable(conn,"review", reviews_table, append = TRUE)
dbWriteTable(conn,"reviewer", reviewers_table, append = TRUE)
}
# ----- Automatically use sample data to create schema
normalise_reviews(reviews_sample)
normalise_listings(listings_sample)
dbGetQuery(conn, "DELETE FROM review")
dbGetQuery(conn, "DELETE FROM reviewer")
dbGetQuery(conn, "DELETE FROM listing")
dbGetQuery(conn, "DELETE FROM host")
start_time <- Sys.time()
folder_path <- "dataset"
listings_list <-list.files(folder_path, pattern = "listings.csv.gz")
reviews_list <-list.files(folder_path, pattern = "reviews.csv.gz")
# ----- Run ETL to normalise listings.csv.gz and store in a relational schema
for (i in 1:length(listings_list)) {
file_path <-paste(folder_path, listings_list[i],sep="/")
listings_data <- read_csv(file_path)
listings_data$file_name <-listings_list[i]
normalise_listings(listings_data) # call function built especially to normalise listings
}
# ----- Run ETL to normalise reviews.csv.gz and store in a relational schema
for (i in 1:length(reviews_list)) {
file_path <-paste(folder_path, reviews_list[i],sep="/")
reviews_data <- read_csv(file_path)
reviews_data$file_name <- reviews_list[i]
}
dbListTables(conn) # list all table names
end_time <- Sys.time()
end_time - start_time #record how long it takes
rm(list = ls()) # cleans the memory
library(xml2)
library(rvest)
library(stringr)
library(dplyr)
library(tm)
library(qdap) # Quantitative Discourse Analysis Package
library(ggplot2)
library(tidyr)
library(RCurl) # download files
library(readr) # read from zip
library(stringr)
library(RSQLite)
# library(plyr)
conn <- dbConnect(RSQLite::SQLite(), "inside_airbnb.db") # connect to SQLite db, in this case, it created a new db
dbGetQuery(conn, "SELECT count(*) FROM listing")
dbGetQuery(conn, "SELECT count(*) FROM review")
dbGetQuery(conn, "SELECT count(*) FROM review")
dbGetQuery(conn, "SELECT count(*) FROM review")
rm(list = ls()) # cleans the memory
library(xml2)
library(rvest)
library(stringr)
library(dplyr)
library(tm)
library(qdap) # Quantitative Discourse Analysis Package
library(ggplot2)
library(tidyr)
library(RCurl) # download files
library(readr) # read from zip
library(stringr)
library(RSQLite)
# library(plyr)
conn <- dbConnect(RSQLite::SQLite(), "inside_airbnb.db")
dbGetQuery(conn, "SELECT count(*) FROM review")
dbGetQuery(conn, "SELECT count(*) FROM listing")
dbGetQuery(conn, "SELECT count(*) FROM listing")
start_time <- Sys.time()
folder_path <- "dataset"
listings_list <-list.files(folder_path, pattern = "listings.csv.gz")
reviews_list <-list.files(folder_path, pattern = "reviews.csv.gz")
# ----- Run ETL to normalise reviews.csv.gz and store in a relational schema
for (i in 1:length(reviews_list)) {
file_path <-paste(folder_path, reviews_list[i],sep="/")
reviews_data <- read_csv(file_path)
reviews_data$file_name <- reviews_list[i]
normalise_reviews(reviews_data)
}
normalise_reviews <- function(reviews_data) {
reviewers_table <- reviews_data %>%
distinct(reviewer_id, reviewer_name)
reviews_table <- reviews_data %>%
select(-reviewer_name)
dbWriteTable(conn,"review", reviews_table, append = TRUE)
dbWriteTable(conn,"reviewer", reviewers_table, append = TRUE)
}
start_time <- Sys.time()
folder_path <- "dataset"
listings_list <-list.files(folder_path, pattern = "listings.csv.gz")
reviews_list <-list.files(folder_path, pattern = "reviews.csv.gz")
# ----- Run ETL to normalise reviews.csv.gz and store in a relational schema
for (i in 1:length(reviews_list)) {
file_path <-paste(folder_path, reviews_list[i],sep="/")
reviews_data <- read_csv(file_path)
reviews_data$file_name <- reviews_list[i]
normalise_reviews(reviews_data)
}
dbListTables(conn) # list all table names
end_time <- Sys.time()
end_time - start_time #record how long it takes
dbGetQuery(conn, "SELECT * FROM review limit 5")
dbGetQuery(conn, "SELECT count(*) FROM review")
rm(list = ls()) # cleans the memory
library(xml2)
library(rvest)
library(stringr)
library(dplyr)
library(tm)
library(qdap) # Quantitative Discourse Analysis Package
library(ggplot2)
library(tidyr)
library(RCurl) # download files
library(readr) # read from zip
library(stringr)
library(RSQLite)
# library(plyr)
# ----- Pre-ETL investigation to get all columns and select the columns needed
# Create a function to make a sample of 1 row from each dataset and combine them to get an idea what columns we have
get_sample <- function(folder_path, pattern) {
listed_files <- list.files(folder_path, pattern = pattern)
main_df <- data.frame()
for (i in 1:length(listed_files)) {
file_path <-paste(folder_path, listed_files[i],sep="/")
local_df <- read.csv(file_path, nrows= 1, stringsAsFactors=FALSE)
local_df$file_name <-listed_files[i]
main_df <- plyr::rbind.fill(main_df, local_df)
}
return(main_df)
}
# Generate the sample
listings_sample <- get_sample(folder_path = "dataset", pattern = "listings.csv.gz")
reviews_sample <- get_sample(folder_path = "dataset", pattern = "reviews.csv.gz")
# ----- Initiation
conn <- dbConnect(RSQLite::SQLite(), "inside_airbnb.db") # connect to SQLite db, in this case, it created a new db
# ----- Build ETL workflow for listings data and reviews data
normalise_listings <- function(listings_data) {
hosts_table <- listings_data %>%
select(starts_with('host')) %>%
distinct(host_id, .keep_all = TRUE)
listings_table <- listings_data %>%
select(-c(contains('url'), host_name:host_identity_verified))
dbWriteTable(conn,"host", hosts_table, append = TRUE)
dbWriteTable(conn,"listing", listings_table, append = TRUE)
}
normalise_reviews <- function(reviews_data) {
reviewers_table <- reviews_data %>%
distinct(reviewer_id, reviewer_name)
reviews_table <- reviews_data %>%
select(-reviewer_name)
dbWriteTable(conn,"review", reviews_table, append = TRUE)
dbWriteTable(conn,"reviewer", reviewers_table, append = TRUE)
}
# ----- Automatically use sample data to create schema
normalise_reviews(reviews_sample)
normalise_listings(listings_sample)
# ----- Clear tables, ready to be inserted.
dbGetQuery(conn, "DELETE FROM review")
dbGetQuery(conn, "DELETE FROM reviewer")
dbGetQuery(conn, "DELETE FROM listing")
dbGetQuery(conn, "DELETE FROM host")
start_time <- Sys.time()
folder_path <- "dataset"
listings_list <-list.files(folder_path, pattern = "listings.csv.gz")
reviews_list <-list.files(folder_path, pattern = "reviews.csv.gz")
# ----- Run ETL to normalise listings.csv.gz and store in a relational schema
for (i in 1:length(listings_list)) {
file_path <-paste(folder_path, listings_list[i],sep="/")
listings_data <- read_csv(file_path)
listings_data$file_name <-listings_list[i]
normalise_listings(listings_data) # call function built especially to normalise listings
}
# ----- Run ETL to normalise reviews.csv.gz and store in a relational schema
for (i in 1:length(reviews_list)) {
file_path <-paste(folder_path, reviews_list[i],sep="/")
reviews_data <- read_csv(file_path)
reviews_data$file_name <- reviews_list[i]
normalise_reviews(reviews_data)
}
dbListTables(conn) # list all table names
end_time <- Sys.time()
end_time - start_time #record how long it takes
dbGetQuery(conn, "SELECT count(*) From listing")
dbGetQuery(conn, "SELECT count(*) From review")
dbGetQuery(conn, "SELECT count(distinct file_name) From listing")
