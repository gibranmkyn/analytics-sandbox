---
title: "text_partB"
author: "Gibran Makyanie"
date: "08/03/2020"
output: html_document
---


```{r}
rm(list = ls())
library(RSQLite)
library(udpipe)
library(cld3)
library(tm)
library(ggplot2)
library(gridExtra)
library(stm)
library(quanteda)
library(textfeatures)
library(sentimentr)
library(qdap)
library(lubridate)3
library(stargazer)
library(readr)
library(dplyr)
library(tidyr)
```


Sources: 
https://cran.r-project.org/web/packages/textfeatures/textfeatures.pdf
https://datascienceplus.com/automated-text-feature-engineering-using-textfeatures-in-r/


```{r}

# ----- Data Importing
conn <- dbConnect(RSQLite::SQLite(), "dataset/inside_airbnb.db") 


# ----- Select listings
listing_sample <- dbGetQuery(conn, 'SELECT * FROM listing limit 500') %>%
  mutate(lang = detect_language(description)) %>% 
  dplyr::rename(listing_id = id) %>%
  filter(lang == 'en') %>%
  mutate(listing_id = as.character(listing_id)) %>%
  mutate(calendar_last_scraped = as_date(as.integer(calendar_last_scraped))) %>%
  group_by(listing_id) %>%
  mutate(calendar_last_scraped_latest = max(calendar_last_scraped)) %>%
  filter(calendar_last_scraped_latest == calendar_last_scraped) %>%
  select(-calendar_last_scraped_latest) %>%
  filter(number_of_reviews > 10)
  

# ----- Select owners of the listings
host_distinct <- unique(listing_sample$host_id)
host_sample <- dbGetQuery(conn, paste('SELECT host_id, host_name FROM host WHERE host_id IN(', paste(host_distinct, collapse = ","), ')'))  %>% 
  distinct(host_id, host_name)


# ----- Select reviews of the listings
listing_distinct <- listing_sample %>%  distinct(listing_id)

review_sample <- dbGetQuery(conn,paste('SELECT * FROM review WHERE listing_id IN', substring(paste(listing_distinct,collapse = ","),2))) %>%
  dplyr::rename(review_id = id) %>%
  mutate(review_id = as.character(review_id)) %>%
  mutate(lang = detect_language(comments)) %>%
  mutate(date = as_date(date)) %>%
  mutate(listing_id = as.character(listing_id)) %>%
  filter(lang == 'en') 



dbDisconnect(conn)


rm(listing_distinct)
rm(host_distinct)
```


```{r}
reviewsNum <- review_sample %>% group_by(date = review_sample$date) %>% summarise(number = n())

ggplot(reviewsNum, aes(date, number)) +
           geom_point(na.rm=TRUE, color = "#007A87", alpha=0.5) +geom_smooth(color = "#FF5A5F")+
  ggtitle("How popular is Airbnb?",
          subtitle = "Number of Reviews across years") +
  labs(x = "Year", y = "Unique listings recieving reviews") +
  theme(plot.title = element_text(face = "bold")) +
  theme(plot.subtitle = element_text(face = "bold", color = "grey35")) +
  theme(plot.caption = element_text(color = "grey68"))

rm(reviewsNum)
```


# Data Prep
```{r}

added_stop_words <- c('amsterdam', 'apartment', 'place', 'house','room', 'stay', 'airbnb','bnb')
clean_corpus <- function(corpus){
  corpus <- tm_map(corpus, removePunctuation)
  corpus <- tm_map(corpus, content_transformer(tolower))
  corpus <- tm_map(corpus, removeWords, words = c(stopwords("en"), added_stop_words))
  corpus <- tm_map(corpus, stripWhitespace)
  corpus <- tm_map(corpus, removeNumbers)
  return(corpus)
}

```




# Text Feature Extraction for reviews data


Sentimentr attempts to take into account valence shifters (i.e.,negators, amplifiers (intensifiers), de-amplifiers (downtoners), and adversative conjunctions) while maintaining speed.


# # Annotate Reviews
```{r }
# ----- Clean comments
x <- VCorpus(VectorSource(review_sample$comments))
x <- clean_corpus(x)
cleaned_comments <- as.data.frame(x) # qdap's function to convert corpus to df
review_sample$cleaned_comments <- cleaned_comments$text

rm(x)
rm(cleaned_comments)

# ----- tokennise, lemmatise, and POS tag per listing
ud_model <- udpipe_download_model(language = "english")
ud_model <- udpipe_load_model(ud_model$file_model)
review_annotate <- data.frame(udpipe_annotate(ud_model, x = review_sample$cleaned_comments, doc_id = review_sample$review_id)) 

x <- review_annotate %>%
  filter(upos %in% c("ADV","ADJ","NOUN", "AUX", "PART")) %>% # aux and part to capture negations 'did not'
  dplyr::rename(review_id = doc_id) %>%
  mutate(review_id = as.character(review_id)) %>%
  dplyr::group_by(review_id) %>%
  summarise(lemma_reviews = paste(lemma, collapse = " "))

review_sample <- review_sample %>% left_join(x)
rm(x)
rm(ud_model)
```


textfeatures function can easily extract generic features (e.g., number of words, line breaks, characters per word, lower case, upper case, commas, periods, exclamation points, etc.) from strings of text with a considerable good speed.
```{r}
# ----- Get features from uncleaned comments
features <- textfeatures(review_sample$comments, normalize = FALSE, word_dims = FALSE, sentiment = TRUE)

# ----- Get sentiment from cleaned comments with sentimentr package
text <- get_sentences(review_sample$lemma_reviews)
review_sample$sentimentr <- as.data.frame(sentiment_by(text))$ave_sentiment

# ----- Whether host name is mentioned in the comments
review_sample <- review_sample %>%
  left_join(listing_sample %>% select(listing_id, host_id)) %>% 
  left_join(host_sample %>% distinct(host_id, host_name)) %>%
  mutate(host_mentioned = as.numeric(grepl(host_name,comments, ignore.case = TRUE)))

# ----- DF about comments features
review_sample <-  bind_cols(review_sample, features)


hist(review_sample$sentimentr, breaks = 200)
hist(review_sample$sent_bing, breaks = 200)
hist(review_sample$sent_afinn, breaks = 200)
hist(review_sample$sent_vader, breaks = 200)
hist(review_sample$n_polite, breaks = 200)
hist(review_sample$n_chars, breaks = 200)
```


```{r}
# ----- Features from review
review_features <- review_sample %>%
  mutate(year_month =  format(date,"%Y-%m"), year_month_back = format(date - years(1), "%Y-%m")) %>%
  select(-c(reviewer_id, host_name)) %>%
  group_by(listing_id, file_name, year_month, year_month_back) %>%
  summarise_if(is.numeric, mean, na.rm = TRUE)


rm(text)
rm(features)
```


https://cran.r-project.org/web/packages/sentimentr/readme/README.html


# Text Feature Extraction for listing_data
```{r}
remove_columns <- c('street', 'neighbourhood', 'neighbourhood_group_cleansed', 'market', 'latitude','longitude', 'is_location_exact', 'square_feet', 'license', 'calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms','reviews_per_month', 'last_searched', 'region_id', 'region_name', 'region_parent_id', 'region_parent_name', 'region_parent_parent_id', 'region_parent_parent_name', 'price', 'weekly_price', 'monthly_price', 'minimum_nights', 'maximum_nights', 'minimum_minimum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights', 'maximum_maximum_nights', 'has_availability')

listing <- listing_sample %>%
  select(-remove_columns) %>%
  unite(col=new_description,c(summary,description,neighborhood_overview, amenities),sep = " ", na.rm=TRUE)


# ----- Clean Listing Description
x <- VCorpus(VectorSource(listing$new_description))
x <- clean_corpus(x)
cleaned_description <- as.data.frame(x) # qdap's function to convert corpus to df
listing$cleaned_description <- cleaned_description$text

rm(x)
rm(cleaned_description)


  
```




```{r}
library(text2vec)

t1 <- Sys.time()

# define preprocessing function and tokenization function
prep_fun <- tolower
tok_fun <- word_tokenizer
term_min <- round(length(listing$cleaned_description)*0.05)

it_train <- itoken(listing$cleaned_description, 
             preprocessor = prep_fun, 
             tokenizer = tok_fun, 
             ids = listing$listing_id, 
             progressbar = TRUE)
vocab <- create_vocabulary(it_train, ngram = c(1L, 2L))



pruned_vocab <- prune_vocabulary(vocab, 
                                 term_count_min = term_min, 
                                 doc_proportion_max = 0.5,
                                 doc_proportion_min = 0.001)

vectorizer <- vocab_vectorizer(pruned_vocab)

dtm_train  <- create_dtm(it_train, vectorizer)

tfidf <- TfIdf$new()

dtm_train_tfidf <- fit_transform(dtm_train, tfidf)
summary(dtm_train_tfidf)

x <- as.data.frame(as.matrix(dtm_train_tfidf))
colnames(x) <- paste0(colnames(x), ("_word__"))
x$listing_id <- rownames(x)

listing_features <- listing %>%
  inner_join(x, by = 'listing_id')




t2 <- Sys.time()
t2 - t1
```




# Feature Extraction from calendar
```{r}
# ----- dataprep calendar
ams_calendar2020 <- read_csv('temp/amsterdam_012020_calendar.csv.gz') %>% select(listing_id, date, available, price)
ams_calendar2019 <- read_csv('temp/amsterdam_012019_calendar.csv.gz') %>% select(listing_id, date, available, price)
ams_calendar2018 <- read_csv('temp/amsterdam_042018_calendar.csv.gz') %>% select(listing_id, date, available, price)

ams_calendar2020 %>%
  filter(year(date) == 2020)


combinedCalendar <- rbind(ams_calendar2020, ams_calendar2019, ams_calendar2018) %>% 
  filter(year(date) <= 2019) %>%
  mutate(booked = ifelse(available==FALSE, 1, 0)) %>%
  mutate(price = as.numeric(gsub(",", "", substring(price, 2))))  %>%
  mutate(listing_id = as.character(listing_id))

rm(ams_calendar2020)
rm(ams_calendar2019)
rm(ams_calendar2018)

library(zoo)

calendar_features <- combinedCalendar %>% 
 arrange(listing_id, desc(date)) %>%
 mutate(price_filled = na.locf(price), year_month =  format(date,"%Y-%m")) %>%
 group_by(listing_id, year_month) %>%
 summarise(total_booked = sum(booked, na.rm = TRUE), total_dates = n(), average_price = mean(price_filled, na.rm = TRUE)) %>%
 mutate(percent_booked = (total_booked/total_dates)*100) %>%
 select(-c(total_booked, total_dates))

```


# Final dataframe
```{r}

final_df <- calendar_features %>%
  inner_join(listing_features, by = 'listing_id') %>%
  inner_join(review_features, by = 'listing_id')

```

# Sentiment Model
```{r}
# Bing Liu
model1 <- lm(log(average_price)~lag(sentimentr), 
             data=final_df)

# NRC affection 
model2 <- lm(log(average_price)~lag(sent_afinn), 
             data=final_df)
#Afinn 
model3 <- lm(log(average_price)~lag(sent_syuzhet), 
             data=final_df)

model4 <- lm(log(average_price)~lag(sent_vader), 
             data=final_df)

stargazer::stargazer(model1,model2,model3,model4,type = "text")
```



# Model Unstructured + Structured Data

```{r}

# ----- Data Prep for the plot
data_with_tfidfmatrix <- select_if(listing_features,is.numeric) %>% 
  inner_join(calendar_features, by = 'listing_id') %>%
  ungroup() %>%
  select(-c(listing_id, host_id))

data_without_tfidfmatrix <- select_if(listing,is.numeric) %>% 
  inner_join(calendar_features, by = 'listing_id') %>% 
  ungroup() %>%
  select(-c(listing_id, host_id))

# ----- Building the models
modelx <- lm(log(average_price)~., data = data_with_tfidfmatrix)

modely <- lm(log(average_price)~., data = data_without_tfidfmatrix)

# ----- Plot the most significant variables
head(as.data.frame(summary(modelx)$coefficients) %>%
  tibble::rownames_to_column() %>%
  mutate(`absolute t value` = abs(`t value`)) %>%
  arrange(`Pr(>|t|)`) , 30) %>%
  mutate(rowname=factor(rowname, levels=rowname)) %>%
  ggplot(aes(x = rowname, y = `absolute t value`)) + geom_col() + coord_flip()


head(as.data.frame(summary(modely)$coefficients) %>%
  tibble::rownames_to_column() %>%
  mutate(`absolute t value` = abs(`t value`)) %>%
  arrange(`Pr(>|t|)`) , 30) %>%
  mutate(rowname=factor(rowname, levels=rowname)) %>%
  ggplot(aes(x = rowname, y = `absolute t value`)) + geom_col() + theme(axis.text.x = element_text(angle = 60, hjust = 1))

print(paste(deparse(substitute(modelx)), 'Adjusted R-squared', summary(modelx)$adj.r.squared))
print(paste(deparse(substitute(modely)), 'Adjusted R-squared', summary(modely)$adj.r.squared))


```









# Predicting Price with Beta Regression


```{r}
reviewsNum <- review_sample %>% group_by(date = review_sample$date) %>% summarise(number = n())

ggplot(reviewsNum, aes(date, number)) +
           geom_point(na.rm=TRUE, color = "#007A87", alpha=0.5) +geom_smooth(color = "#FF5A5F")+
  ggtitle("How popular is Airbnb?",
          subtitle = "Number of Reviews across years") +
  labs(x = "Year", y = "Unique listings recieving reviews") +
  theme(plot.title = element_text(face = "bold")) +
  theme(plot.subtitle = element_text(face = "bold", color = "grey35")) +
  theme(plot.caption = element_text(color = "grey68"))

rm(reviewsNum)
```


```{r}
ggplot(data = final_df, aes(x = sentimentr, y = review_scores_rating)) + 
  geom_jitter() +
  geom_smooth()


final_df %>%
  filter(review_scores_rating == 100)


model1 <- lm(log(final_df$review_scores_rating)~final_df$sent_bing)
model2 <- lm(log(final_df$review_scores_rating)~final_df$sent_afinn)
model3 <- lm(log(final_df$review_scores_rating)~final_df$sentimentr)
plot(model1)

stargazer(model1,model2,model3,type = "text")

ggplot(final_df, aes())


```

```{r}
grid.arrange(
review_annotate %>%
  filter(upos %in% c('NOUN')) %>%
  group_by(lemma) %>%
  summarise(freq = n()) %>%
  arrange(desc(freq)) %>%
  head(n =20) %>%
  mutate(lemma=factor(lemma, levels=lemma)) %>%
  ggplot(aes(x=lemma, y = freq )) + geom_col() + coord_flip(),

review_annotate %>%
  filter(upos %in% c('ADJ')) %>%
  group_by(lemma) %>%
  summarise(freq = n()) %>%
  arrange(desc(freq)) %>%
  head(n =20) %>%
  mutate(lemma=factor(lemma, levels=lemma)) %>%
  ggplot(aes(x=lemma, y = freq )) + geom_col() + coord_flip(),


review_annotate %>%
  filter(upos %in% c('ADV')) %>%
  group_by(lemma) %>%
  summarise(freq = n()) %>%
  arrange(desc(freq)) %>%
  head(n =20) %>%
  mutate(lemma=factor(lemma, levels=lemma)) %>%
  ggplot(aes(x=lemma, y = freq )) + geom_col() + coord_flip()
)
```


# Calendar Data

```{r}
groupedCalendarAll <- combinedCalendar %>%
  group_by(date = date) %>% 
  summarise(average_price = mean(price, na.rm = TRUE)) %>% 
  mutate(year = as.factor(as.character(year(date))))


# ----- Plotting Seasonality in Price
ggplot(groupedCalendarAll, aes(x = month(date), y=average_price)) +
           geom_point(na.rm=TRUE, alpha=0.5, color = "#007A87") + geom_smooth(color = "#FF5A5F")+ facet_grid(~year)+
  ggtitle("Seasonality in Price",
          subtitle = "Average listing price across Months") +
  labs(x = "Month", y = "Average price across Listings") +
  theme(plot.title = element_text(face = "bold")) +
  theme(plot.subtitle = element_text(face = "bold", color = "grey35")) +
  scale_x_continuous(breaks = c(3, 6, 9, 12))

rm(groupedCalendarAll)
```

# Occupancy Rate
```{r}
airbnb_occ_rate <- combinedCalendar %>% 
  group_by(date = date) %>% 
  summarise(totalBooked = sum(booked, na.rm = TRUE), totalListings = n()) %>% 
  mutate(percent_booked = (totalBooked/totalListings)*100) %>%
  mutate(year = year(date))

ggplot(airbnb_occ_rate, aes(x = month(date), y = percent_booked)) +
  geom_jitter(na.rm=TRUE, alpha=0.5, color = "#007A87") +
  geom_smooth(color = "#FF5A5F") +
  facet_grid(~year) +
  ggtitle("Occupancy Rate Overtime") +
  labs(x = "Month", y = "Occupancy Rate") +
  theme(plot.title = element_text(face = "bold")) +
  theme(plot.subtitle = element_text(face = "bold", color = "grey35")) +
  scale_x_continuous(breaks = c(3, 6, 9, 12))

rm(airbnb_occ_rate)

```




