---
title: "text_partB"
author: "Gibran Makyanie"
date: "08/03/2020"
output: html_document
---


```{r}
rm(list = ls())
library(dplyr)
library(RSQLite)
library(udpipe)
library(cld3)
library(tm)
library(ggplot2)
library(gridExtra)
library(stm)
library(quanteda)
library(textfeatures)
library(sentimentr)
library(qdap)
library(lubridate)
library(stargazer)
library(readr)
```


Sources: 
https://cran.r-project.org/web/packages/textfeatures/textfeatures.pdf
https://datascienceplus.com/automated-text-feature-engineering-using-textfeatures-in-r/


```{r}

# ----- Data Importing
conn <- dbConnect(RSQLite::SQLite(), "dataset/inside_airbnb.db") 


# ----- Select listings
listing_sample <- dbGetQuery(conn, 'SELECT * FROM listing limit 500') %>%
  mutate(lang = detect_language(description)) %>% 
  rename(listing_id = id) %>%
  filter(lang == 'en') %>%
  mutate(listing_id = as.character(listing_id)) %>%
  mutate(calendar_last_scraped = as_date(as.integer(calendar_last_scraped))) %>%
  group_by(listing_id) %>%
  mutate(calendar_last_scraped_latest = max(calendar_last_scraped)) %>%
  filter(calendar_last_scraped_latest == calendar_last_scraped) %>%
  select(-calendar_last_scraped_latest) %>%
  filter(number_of_reviews > 10)
  

# ----- Select owners of the listings
host_distinct <- unique(listing_sample$host_id)
host_sample <- dbGetQuery(conn, paste('SELECT host_id, host_name FROM host WHERE host_id IN(', paste(host_distinct, collapse = ","), ')'))  %>% 
  distinct(host_id, host_name)


# ----- Select reviews of the listings
listing_distinct <- listing_sample %>%  distinct(listing_id)

review_sample <- dbGetQuery(conn,paste('SELECT * FROM review WHERE listing_id IN', substring(paste(listing_distinct,collapse = ","),2))) %>%
  mutate(lang = detect_language(comments)) %>%
  mutate(date = as_date(date)) %>%
  mutate(listing_id = as.character(listing_id)) %>%
  filter(lang == 'en') 



dbDisconnect(conn)


rm(listing_distinct)
rm(host_distinct)
```


```{r}
reviewsNum <- review_sample %>% group_by(date = review_sample$date) %>% summarise(number = n())

ggplot(reviewsNum, aes(date, number)) +
           geom_point(na.rm=TRUE, color = "#007A87", alpha=0.5) +geom_smooth(color = "#FF5A5F")+
  ggtitle("How popular is Airbnb?",
          subtitle = "Number of Reviews across years") +
  labs(x = "Year", y = "Unique listings recieving reviews") +
  theme(plot.title = element_text(face = "bold")) +
  theme(plot.subtitle = element_text(face = "bold", color = "grey35")) +
  theme(plot.caption = element_text(color = "grey68"))

rm(reviewsNum)
```


# Data Prep
```{r}

added_stop_words <- c('amsterdam', 'apartment', 'place', 'house','room', 'stay', 'airbnb','bnb')
clean_corpus <- function(corpus){
#  corpus <- tm_map(corpus, removePunctuation)
  corpus <- tm_map(corpus, content_transformer(tolower))
  corpus <- tm_map(corpus, removeWords, words = c(stopwords("en"), added_stop_words ))
  corpus <- tm_map(corpus, stripWhitespace)
  corpus <- tm_map(corpus, removeNumbers)
  return(corpus)
}

```


# Annotate Reviews
```{r}

# ----- Clean comments
x <- VCorpus(VectorSource(review_sample$comments))
x <- clean_corpus(x)
cleaned_comments <- as.data.frame(x) # qdap's function to convert corpus to df
review_sample$cleaned_comments <- cleaned_comments$text

rm(x)
rm(cleaned_comments)

# ----- tokennise, lemmatise, and POS tag per listing
ud_model <- udpipe_download_model(language = "english")
ud_model <- udpipe_load_model(ud_model$file_model)
review_annotate <- data.frame(udpipe_annotate(ud_model, x = review_sample$cleaned_comments, doc_id = review_sample$id)) 

x <- review_annotate %>%
  rename(id = doc_id) %>%
  mutate(id = as.integer(id)) %>%
  group_by(id) %>%
  filter(upos %in% c("ADV","ADJ","NOUN", "AUX", "PART")) %>% # aux and part to capture negations 'did not'
  summarise(lemma_reviews = paste(lemma, collapse = " "))

review_sample <- review_sample %>% left_join(x)

rm(x)
rm(ud_model)
```


# Text Feature Extraction for reviews data
textfeatures function can easily extract generic features (e.g., number of words, line breaks, characters per word, lower case, upper case, commas, periods, exclamation points, etc.) from strings of text with a considerable good speed.
```{r}
# ----- Get features from uncleaned comments
features <- textfeatures(review_sample$comments, normalize = FALSE, word_dims = FALSE, sentiment = TRUE)

# ----- Get sentiment from cleaned comments with sentimentr package
text <- get_sentences(review_sample$lemma_reviews)
review_sample$sentimentr <- as.data.frame(sentiment_by(text))$ave_sentiment


# ----- Whether host name is mentioned in the comments
review_sample <- review_sample %>%
  left_join(listing_sample %>% select(listing_id, host_id)) %>% 
  left_join(host_sample %>% distinct(host_id, host_name)) %>%
  mutate(host_mentioned = as.numeric(grepl(host_name,comments, ignore.case = TRUE)))

# ----- DF about comments features
review_sample <-  bind_cols(review_sample, features)


hist(review_sample$sentimentr, breaks = 200)
hist(review_sample$sent_bing, breaks = 200)
hist(review_sample$sent_afinn, breaks = 200)
hist(review_sample$sent_vader, breaks = 200)
hist(review_sample$n_polite, breaks = 200)
hist(review_sample$n_chars, breaks = 200)

# ----- Aggerate reviews per listing
review_agg <- review_sample %>%
  mutate(year_month =  format(date,"%Y-%m"), year_month_back = format(date - years(1), "%Y-%m")) %>%
  select(-c(reviewer_id, id)) %>%
  group_by(listing_id, file_name, year_month, year_month_back) %>%
  summarise_if(is.numeric, mean, na.rm = TRUE)


rm(text)
rm(features)
```


Sentimentr attempts to take into account valence shifters (i.e.,
negators, amplifiers (intensifiers), de-amplifiers (downtoners), and
adversative conjunctions) while maintaining speed

https://cran.r-project.org/web/packages/sentimentr/readme/README.html


# Text Feature Extraction for listing_data
```{r}
remove_columns <- c('street', 'neighbourhood', 'neighbourhood_group_cleansed', 'market', 'latitude','longitude', 'is_location_exact', 'square_feet', 'license', 'calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms','reviews_per_month', 'last_searched', 'region_id', 'region_name', 'region_parent_id', 'region_parent_name', 'region_parent_parent_id', 'region_parent_parent_name', 'price', 'weekly_price', 'monthly_price', 'minimum_nights', 'maximum_nights', 'minimum_minimum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights', 'maximum_maximum_nights', 'has_availability')

listing_sample <- listing_sample %>%
  select(-remove_columns)


```

```{r}
# ----- Clean comments
listing_sample$amenities

rm(x)
rm(cleaned_text_listings)

# ----- tokennise, lemmatise, and POS tag per listing
ud_model <- udpipe_download_model(language = "english")
ud_model <- udpipe_load_model(ud_model$file_model)
listings_annotate <- data.frame(udpipe_annotate(ud_model, x = listing_sample$amenities, doc_id = listing_sample$listing_id))

x <- review_annotate %>%
  rename(id = doc_id) %>%
  mutate(id = as.integer(id)) %>%
  group_by(id) %>%
  filter(upos %in% c("ADV","ADJ","NOUN", "AUX", "PART")) %>% # aux and part to capture negations 'did not'
  summarise(lemma_reviews = paste(lemma, collapse = " "))

review_sample <- review_sample %>% left_join(x)

rm(x)
rm(ud_model)
```




# Feature Extraction from calendar
```{r}
# ----- dataprep calendar
ams_calendar2020 <- read_csv('temp/amsterdam_012020_calendar.csv.gz') %>% select(listing_id, date, available, price)
ams_calendar2019 <- read_csv('temp/amsterdam_012019_calendar.csv.gz') %>% select(listing_id, date, available, price)
ams_calendar2018 <- read_csv('temp/amsterdam_042018_calendar.csv.gz') %>% select(listing_id, date, available, price)

ams_calendar2020 %>%
  filter(year(date) == 2020)



combinedCalendar <- rbind(ams_calendar2020, ams_calendar2019, ams_calendar2018) %>% 
  filter(year(date) <= 2019) %>%
  mutate(booked = ifelse(available==FALSE, 1, 0)) %>%
  mutate(price = as.numeric(gsub(",", "", substring(price, 2))))  %>%
  mutate(listing_id = as.character(listing_id))

rm(ams_calendar2020)
rm(ams_calendar2019)
rm(ams_calendar2018)

library(zoo)
listings_calendar <- combinedCalendar %>% 
 arrange(listing_id, desc(date)) %>%
 mutate(price_filled = na.locf(price), year_month =  format(date,"%Y-%m")) %>%
 group_by(listing_id, year_month) %>%
 summarise(total_booked = sum(booked, na.rm = TRUE), total_dates = n(), average_price = mean(price_filled, na.rm = TRUE)) %>%
 mutate(percent_booked = (total_booked/total_dates)*100) 
```
```{r}

ggplot(listings_calendar, aes(x = year_month, y = average_price, group = listing_id)) +
  geom_line()
```


# Final dataframe
```{r}

final_df <- listing_sample %>%
#  inner_join(review_agg, by = 'listing_id') %>% # inner join is used to ensure that the selected listings has reviews
  inner_join(listings_calendar %>% select(listing_id, average_price, percent_booked), by = 'listing_id')

#rm(review_agg)
```











# Predicting Price with Beta Regression


```{r}
reviewsNum <- review_sample %>% group_by(date = review_sample$date) %>% summarise(number = n())

ggplot(reviewsNum, aes(date, number)) +
           geom_point(na.rm=TRUE, color = "#007A87", alpha=0.5) +geom_smooth(color = "#FF5A5F")+
  ggtitle("How popular is Airbnb?",
          subtitle = "Number of Reviews across years") +
  labs(x = "Year", y = "Unique listings recieving reviews") +
  theme(plot.title = element_text(face = "bold")) +
  theme(plot.subtitle = element_text(face = "bold", color = "grey35")) +
  theme(plot.caption = element_text(color = "grey68"))

rm(reviewsNum)
```


```{r}
ggplot(data = final_df, aes(x = sentimentr, y = review_scores_rating)) + 
  geom_jitter() +
  geom_smooth()


final_df %>%
  filter(review_scores_rating == 100)


model1 <- lm(log(final_df$review_scores_rating)~final_df$sent_bing)
model2 <- lm(log(final_df$review_scores_rating)~final_df$sent_afinn)
model3 <- lm(log(final_df$review_scores_rating)~final_df$sentimentr)
plot(model1)

stargazer(model1,model2,model3,type = "text")

ggplot(final_df, aes())


```

```{r}
grid.arrange(
review_annotate %>%
  filter(upos %in% c('NOUN')) %>%
  group_by(lemma) %>%
  summarise(freq = n()) %>%
  arrange(desc(freq)) %>%
  head(n =20) %>%
  mutate(lemma=factor(lemma, levels=lemma)) %>%
  ggplot(aes(x=lemma, y = freq )) + geom_col() + coord_flip(),

review_annotate %>%
  filter(upos %in% c('ADJ')) %>%
  group_by(lemma) %>%
  summarise(freq = n()) %>%
  arrange(desc(freq)) %>%
  head(n =20) %>%
  mutate(lemma=factor(lemma, levels=lemma)) %>%
  ggplot(aes(x=lemma, y = freq )) + geom_col() + coord_flip(),


review_annotate %>%
  filter(upos %in% c('ADV')) %>%
  group_by(lemma) %>%
  summarise(freq = n()) %>%
  arrange(desc(freq)) %>%
  head(n =20) %>%
  mutate(lemma=factor(lemma, levels=lemma)) %>%
  ggplot(aes(x=lemma, y = freq )) + geom_col() + coord_flip()
)
```


# Calendar Data

```{r}
groupedCalendarAll <- combinedCalendar %>%
  group_by(date = date) %>% 
  summarise(average_price = mean(price, na.rm = TRUE)) %>% 
  mutate(year = as.factor(as.character(year(date))))


# ----- Plotting Seasonality in Price
ggplot(groupedCalendarAll, aes(x = month(date), y=average_price)) +
           geom_point(na.rm=TRUE, alpha=0.5, color = "#007A87") + geom_smooth(color = "#FF5A5F")+ facet_grid(~year)+
  ggtitle("Seasonality in Price",
          subtitle = "Average listing price across Months") +
  labs(x = "Month", y = "Average price across Listings") +
  theme(plot.title = element_text(face = "bold")) +
  theme(plot.subtitle = element_text(face = "bold", color = "grey35")) +
  scale_x_continuous(breaks = c(3, 6, 9, 12))

rm(groupedCalendarAll)
```

# Occupancy Rate
```{r}
airbnb_occ_rate <- combinedCalendar %>% 
  group_by(date = date) %>% 
  summarise(totalBooked = sum(booked, na.rm = TRUE), totalListings = n()) %>% 
  mutate(percent_booked = (totalBooked/totalListings)*100) %>%
  mutate(year = year(date))

ggplot(airbnb_occ_rate, aes(x = month(date), y = percent_booked)) +
  geom_jitter(na.rm=TRUE, alpha=0.5, color = "#007A87") +
  geom_smooth(color = "#FF5A5F") +
  facet_grid(~year) +
  ggtitle("Occupancy Rate Overtime") +
  labs(x = "Month", y = "Occupancy Rate") +
  theme(plot.title = element_text(face = "bold")) +
  theme(plot.subtitle = element_text(face = "bold", color = "grey35")) +
  scale_x_continuous(breaks = c(3, 6, 9, 12))

rm(airbnb_occ_rate)

```


```{r}
library(superml)

t1 <- Sys.time()
df <- data.frame(sents = c('i am alone in DARK',
                           'mother_mary a lot',
                           'alone in the DARK?',
                           'many mothers in the lot....'))

df <- data.frame(sents = listing_sample$description)[1:2,]

# initialise vectoriser instance
tfidf <- TfIdfVectorizer$new(smooth_idf = TRUE, min_df = 0.3, remove_stopwords = TRUE, ngram_range = c(1,3))


tf_features <- as.data.frame(tfidf$fit_transform(df))

t2 <- Sys.time()

t2-t1
```



```{r}
library(text2vec)

t1 <- Sys.time()
df <- listing_sample %>%
  select(listing_id, description, amenities)

# define preprocessing function and tokenization function
prep_fun = tolower
tok_fun = word_tokenizer

it_train = itoken(final_df$amenities, 
             preprocessor = prep_fun, 
             tokenizer = tok_fun, 
             ids = final_df$listing_id, 
             progressbar = TRUE)
vocab = create_vocabulary(it_train, stopwords = quanteda::stopwords("en"), ngram = c(1L, 2L))

pruned_vocab = prune_vocabulary(vocab, 
                                 term_count_min = 10, 
                                 doc_proportion_max = 0.5,
                                 doc_proportion_min = 0.001)

vectorizer = vocab_vectorizer(pruned_vocab)

dtm_train  = create_dtm(it_train, vectorizer)

tfidf = TfIdf$new()

dtm_train_tfidf = fit_transform(dtm_train, tfidf)
summary(dtm_train_tfidf)

x <- as.data.frame(as.matrix(dtm_train_tfidf))
x$listing_id <- rownames(x)

pred_x <- x %>%
  inner_join(final_df %>% select(listing_id, average_price), by = 'listing_id')

t2 <- Sys.time()
t2 - t1
```


```{r}

library(ridge)


set.seed(100) # set seed to replicate results
trainingIndex <- sample(1:nrow(pred_x), 0.8*nrow(pred_x)) # indices for 80% training data
trainingData <- pred_x[trainingIndex, ] # training data
testData <- pred_x[-trainingIndex, ] # test data


modelx <- linearRidge(log(average_price)~., data = trainingData %>% select(-listing_id))
modely <- lm(log(average_price)~., data = trainingData %>% select(-listing_id))
summary(modelx)
summary(modely)
predicted <- predict(modelx, testData)  # predict on test data
compare <- cbind (actual=testData$response, predicted)  # combine

mean (apply(compare, 1, min)/apply(compare, 1, max)) # calculate accuracy


hist(trainingData$average_price, breaks = 200)

hist(log(trainingData$average_price), breaks = 200)
```

